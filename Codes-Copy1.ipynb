{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7653c6-f3f0-43dc-891b-9fca75b07ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C/P files (not storage friendly..)\n",
    "\n",
    "cp Microcoleus/Community/CAWBG24/*.fa FengMin/CAWBG24.Pro/\n",
    "\n",
    "\n",
    "find Mapping/ -type f -name \"*JU.bins.fna\" -exec rm {} \\;\n",
    "\t•\t.gff: Contains the genome coordinates and functional annotations.\n",
    "\t•\t.faa: Protein sequences in FASTA format.\n",
    "\t•\t.fna: DNA ORFs in FASTA format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f29100-6f12-4da1-bc5c-d4352b0f8457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prokka Annotation \n",
    "\n",
    "cp Microcoleus/Community/CAWBG51/*.fa FengMin/week_3_prokka_pilot/CAWBG51.prok/\n",
    "\n",
    "# Prokka community .fa files using defualt settings\n",
    "Nano prokka_pilot.sh\n",
    "\n",
    "\n",
    "\n",
    "#!/bin/bash -e\n",
    "#SBATCH -A uoa03265\n",
    "#SBATCH -J spades_assembly_01_v2\n",
    "#SBATCH --time 00:30:00\n",
    "#SBATCH --mem 10GB\n",
    "#SBATCH --ntasks 1\n",
    "#SBATCH --cpus-per-task 8\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "\n",
    "# Loop through each directory (assuming they are in the current working directory)\n",
    "for dir in */; do\n",
    "  # Check if the directory exists\n",
    "  if [ -d \"$dir\" ]; then\n",
    "    # Loop through all .fa files in the directory\n",
    "    for fa_file in \"$dir\"*.fa; do\n",
    "      # Extract the filename without the extension\n",
    "      file_name=$(basename \"$fa_file\" .fa)\n",
    "      \n",
    "      # Run Prokka with the output directory and prefix matching the .fa file name\n",
    "      prokka --outdir \"${dir}${file_name}_output\" --prefix \"$file_name\" \"$fa_file\"\n",
    "    done\n",
    "  fi\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d988b39c-9125-430a-bf72-35b5be7d1b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. DNA gene calls (fasta)\t- from Prokka\n",
    "# 2. DNA gene +- flanking regions\t\n",
    "# 3. The flanking regions with the gene deleted \n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --time=23:59:59\n",
    "#SBATCH --mem=35GB\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --output=slurm_%j.out\n",
    "#SBATCH --error=slurm_%j.err\n",
    "\n",
    "# Optional safety toggle — comment out for debugging\n",
    "set -euo pipefail\n",
    "\n",
    "# Loop recursively over all .gff files, excluding .ipynb_checkpoints\n",
    "find . -type f -name \"*.gff\" ! -path \"*/.ipynb_checkpoints/*\" | while read gff_file; do\n",
    "  echo \"Processing file: $gff_file\"\n",
    "  dir=$(dirname \"$gff_file\")\n",
    "  base=$(basename \"$gff_file\" .gff)\n",
    "\n",
    "  fna_file=\"$dir/$base.fna\"\n",
    "  if [ ! -f \"$fna_file\" ]; then\n",
    "    echo \"FASTA file $fna_file does not exist. Skipping.\"\n",
    "    continue\n",
    "  fi\n",
    "\n",
    "  # Output file names\n",
    "  gene_fasta=\"$dir/${base}_gene_only.fa\"\n",
    "  full_fasta=\"$dir/${base}_gene_with_flanks.fa\"\n",
    "  del_fasta=\"$dir/${base}_gene_deletion.fa\"\n",
    "\n",
    "  # Clear old contents\n",
    "  > \"$gene_fasta\"\n",
    "  > \"$full_fasta\"\n",
    "  > \"$del_fasta\"\n",
    "\n",
    "  # Make sure fasta index exists\n",
    "  samtools faidx \"$fna_file\"\n",
    "\n",
    "  # Process each CDS from the GFF\n",
    "  awk 'BEGIN { FS=\"\\t\"; OFS=\"\\t\" }\n",
    "  $3==\"CDS\" {\n",
    "    locus = \"NA\";\n",
    "    product = \"NA\";\n",
    "    attr = $9;\n",
    "    if (sub(/.*locus_tag=/, \"\", attr)) {\n",
    "      locus = attr; sub(/;.*/, \"\", locus);\n",
    "    }\n",
    "    attr = $9;\n",
    "    if (sub(/.*product=/, \"\", attr)) {\n",
    "      product = attr; sub(/;.*/, \"\", product);\n",
    "    }\n",
    "    orig_start = $4;\n",
    "    orig_end = $5;\n",
    "    strand = $7;\n",
    "    full_start = orig_start - 250;\n",
    "    if (full_start < 1) full_start = 1;\n",
    "    full_end = orig_end + 250;\n",
    "    print $1, orig_start, orig_end, full_start, full_end, locus, strand, product;\n",
    "  }' \"$gff_file\" | while read seq_id orig_start orig_end full_start full_end locus strand product; do\n",
    "\n",
    "    # --- Extract gene only ---\n",
    "    gene_seq=$(samtools faidx \"$fna_file\" \"${seq_id}:${orig_start}-${orig_end}\" | tail -n +2 | tr -d '\\n')\n",
    "    if [ \"$strand\" = \"-\" ]; then\n",
    "      gene_seq=$(echo \"$gene_seq\" | rev | tr 'ACGTacgt' 'TGCAtgca')\n",
    "    fi\n",
    "\n",
    "    gene_len=${#gene_seq}\n",
    "    if [ \"$gene_len\" -lt 500 ]; then\n",
    "      continue  # skip short genes\n",
    "    fi\n",
    "\n",
    "    # --- Output gene_only ---\n",
    "    header_gene=\">${locus} ${product} | start:${orig_start} stop:${orig_end} | strand:${strand} | gene_only\"\n",
    "    echo \"$header_gene\" >> \"$gene_fasta\"\n",
    "    echo \"$gene_seq\" >> \"$gene_fasta\"\n",
    "\n",
    "    # --- Extract full gene + flanks ---\n",
    "    full_seq=$(samtools faidx \"$fna_file\" \"${seq_id}:${full_start}-${full_end}\" | tail -n +2 | tr -d '\\n')\n",
    "    if [ \"$strand\" = \"-\" ]; then\n",
    "      full_seq=$(echo \"$full_seq\" | rev | tr 'ACGTacgt' 'TGCAtgca')\n",
    "    fi\n",
    "    header_full=\">${locus} | start:${orig_start} stop:${orig_end} | strand:${strand} | full_start:${full_start} full_end:${full_end} | product:${product} | gene_with_flanks\"\n",
    "    echo \"$header_full\" >> \"$full_fasta\"\n",
    "    echo \"$full_seq\" >> \"$full_fasta\"\n",
    "\n",
    "    # --- Extract flanks only (simulate deletion) ---\n",
    "    if [ \"$orig_start\" -gt \"$full_start\" ]; then\n",
    "      upstream=$(samtools faidx \"$fna_file\" \"${seq_id}:${full_start}-$((orig_start - 1))\" | tail -n +2 | tr -d '\\n')\n",
    "    else\n",
    "      upstream=\"\"\n",
    "    fi\n",
    "\n",
    "    if [ \"$orig_end\" -lt \"$full_end\" ]; then\n",
    "      downstream=$(samtools faidx \"$fna_file\" \"${seq_id}:$((orig_end + 1))-${full_end}\" | tail -n +2 | tr -d '\\n')\n",
    "    else\n",
    "      downstream=\"\"\n",
    "    fi\n",
    "\n",
    "    del_seq=\"${upstream}${downstream}\"\n",
    "    if [ \"$strand\" = \"-\" ]; then\n",
    "      del_seq=$(echo \"$del_seq\" | rev | tr 'ACGTacgt' 'TGCAtgca')\n",
    "    fi\n",
    "    header_del=\">${locus} ${product} | start:${orig_start} stop:${orig_end} | strand:${strand} | flanking_deletion(+/-250bp)\"\n",
    "    echo \"$header_del\" >> \"$del_fasta\"\n",
    "    echo \"$del_seq\" >> \"$del_fasta\"\n",
    "\n",
    "  done\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a68d2e6-2e59-40b3-b1be-ec30e8576b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Readmapping \n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --time=48:59:59\n",
    "#SBATCH --mem=15GB\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=8\n",
    "\n",
    "\n",
    "\n",
    "for dir in 0*/ 10*/ 11*/; do\n",
    "    # Verify that we are working with a directory.\n",
    "    [[ -d \"$dir\" ]] || continue\n",
    "    # Remove trailing slash from the directory name.\n",
    "    dir=\"${dir%/}\"\n",
    "    \n",
    "    echo \"------------------------------\"\n",
    "    echo \"Processing directory: $dir\"\n",
    "    \n",
    "    ###############################\n",
    "    # Step 1: Concatenate *.fa files from bowtie_fas into JUJU.bins.fna\n",
    "    if [ -d \"$dir/bowtie_fas\" ]; then\n",
    "        if [ -f \"$dir/JUJU.bins.fna\" ]; then\n",
    "            echo \"  Removing existing $dir/JUJU.bins.fna...\"\n",
    "            rm \"$dir/JUJU.bins.fna\"\n",
    "        fi\n",
    "        echo \"  Concatenating files in $dir/bowtie_fas to create JUJU.bins.fna...\"\n",
    "        cat \"$dir/bowtie_fas/\"*.fa >> \"$dir/JUJU.bins.fna\"\n",
    "    else\n",
    "        echo \"  Skipping concatenation: No bowtie_fas directory found in $dir.\"\n",
    "    fi\n",
    "\n",
    "    ###############################\n",
    "    # Step 2: Build bowtie2 index\n",
    "    if [ -f \"$dir/JUJU.bins.fna\" ]; then\n",
    "        # Ensure the output directory exists.\n",
    "        mkdir -p \"$dir/bin_coverage\"\n",
    "        \n",
    "        # Remove any existing bowtie2 index files (with names like JUJU.bins.1.bt2, etc.).\n",
    "        if ls \"$dir/bin_coverage/JUJU.bins\".*.bt2 1> /dev/null 2>&1; then\n",
    "            echo \"  Removing existing bowtie2 index files in $dir/bin_coverage...\"\n",
    "            rm \"$dir/bin_coverage/JUJU.bins\".*.bt2\n",
    "        fi\n",
    "\n",
    "        echo \"  Running bowtie2-build for $dir...\"\n",
    "        bowtie2-build \"$dir/JUJU.bins.fna\" \"$dir/bin_coverage/JUJU.bins\"\n",
    "    else\n",
    "        echo \"  Skipping bowtie2-build: No JUJU.bins.fna file found in $dir.\"\n",
    "    fi\n",
    "\n",
    "    ###############################\n",
    "    # Step 3: Align reads and process BAM files\n",
    "    # Extract numeric prefix from the directory name.\n",
    "    num=$(basename \"$dir\" | grep -oE '^[0-9]+')\n",
    "    if [ -z \"$num\" ]; then\n",
    "        echo \"  Skipping alignment: No numeric prefix found in $dir.\"\n",
    "        continue\n",
    "    fi\n",
    "    # Format the number to two digits (e.g. 9 -> 09)\n",
    "    num=$(printf \"%02d\" \"$num\")\n",
    "    \n",
    "    # Define read files and outputs.\n",
    "    reads_dir=\"$dir/Reads\"\n",
    "    fq1=\"$reads_dir/t.${num}.1.fastq.gz\"\n",
    "    fq2=\"$reads_dir/t.${num}.2.fastq.gz\"\n",
    "    index=\"$dir/bin_coverage/JUJU.bins\"\n",
    "    sam_output=\"$dir/bin_coverage/output_${num}.sam\"\n",
    "    bam_output=\"$dir/bin_coverage/output_${num}.bam\"\n",
    "    depth_output=\"$dir/bin_coverage/bins_cov_table_${num}.txt\"\n",
    "    \n",
    "    # Check for the necessary files: paired-end reads and bowtie2 index (index.1.bt2 must exist).\n",
    "    if [[ -f \"$fq1\" && -f \"$fq2\" && -f \"$index.1.bt2\" ]]; then\n",
    "        echo \"  Running Bowtie2 alignment for $dir...\"\n",
    "        bowtie2 -x \"$index\" -1 \"$fq1\" -2 \"$fq2\" -S \"$sam_output\"\n",
    "        echo \"  Bowtie2 alignment completed for $dir.\"\n",
    "    \n",
    "        echo \"  Sorting SAM into BAM for $dir...\"\n",
    "        samtools sort -o \"$bam_output\" \"$sam_output\"\n",
    "        echo \"  SAM sorting completed for $dir.\"\n",
    "    \n",
    "        echo \"  Summarizing BAM contig depths for $dir...\"\n",
    "        jgi_summarize_bam_contig_depths --outputDepth \"$depth_output\" \"$dir/bin_coverage/\"*.bam\n",
    "        echo \"  Depth summarization completed for $dir.\"\n",
    "    else\n",
    "        echo \"  Skipping alignment and downstream processing for $dir: Missing required files (reads or index).\"\n",
    "    fi\n",
    "\n",
    "    echo \"Finished processing $dir.\"\n",
    "done\n",
    "\n",
    "echo \"All processes completed successfully!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bea3a54-ee68-4963-9b7c-d48a25f0dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Depth Visualisation \n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --time=48:59:59\n",
    "#SBATCH --mem=15GB\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=8\n",
    "\n",
    "for f in *.bam; do\n",
    "  samtools depth \"$f\" > \"${f%.bam}.depth\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18145885-0175-400b-b42e-649355127160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#R Studio \n",
    "coverage_targets <- read.table(file = \"cov_targets.txt\", header = FALSE)\n",
    "depth_file <- \"output_08.depth\"\n",
    "\n",
    "data <- read.table(depth_file, header = FALSE, )\n",
    "\n",
    "\n",
    "for (b in 1:nrow(coverage_targets)){\n",
    "\tx <- vector()\n",
    "\ty <- vector()\n",
    "\tcnt = 1\n",
    "\tfor (a in 1:nrow(data)){\n",
    "\t\tif(data[a,1] == coverage_targets[b,1]){ \n",
    "\t\t\tx[cnt] = data[a,2]\n",
    "\t\t\ty[cnt] = data[a,3]\n",
    "\t\t\tcnt = cnt + 1\n",
    "\t\t}\t\n",
    "\t}\n",
    "\tout_head <- \"bp\\tread depth\"\n",
    "\tout_file <- paste(coverage_targets[b,1], \"bp-depth\", sep = \".\")\n",
    "\twrite(out_head, file = out_file)\n",
    "\tfor (z in 1:cnt){\n",
    "\t\tout_ln <- paste(x[z], y[z], sep = \"\\t\")\n",
    "\t\twrite(out_ln, file = out_file, append = TRUE)\n",
    "\t}\n",
    "}\n",
    "\n",
    "in_files <- list.files(pattern = \"*.bp-depth\")\n",
    "for (y in 1:length(in_files)){\n",
    "\tfiln <- read.table(in_files[y], header = TRUE, sep = \"\\t\")\n",
    "\tpdf_name <- paste(in_files[y], \"pdf\", sep = \".\")\n",
    "\tpdf(pdf_name)\n",
    "\tplot(filn, type = \"l\", xlab = \"coordinate\", ylab = \"depth\")\n",
    "\tdev.off()\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 (gimkl-2022a)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
